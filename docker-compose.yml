services:
  valkey:
    image: valkey/valkey-extensions:8.1-bookworm
    ports: ["6379:6379"]
    healthcheck:
      test: ["CMD", "valkey-cli", "MODULE", "LIST", "|", "grep", "-q", "json"]
      interval: 5s
      retries: 5

  # ─────────────────────────── shared image layers ────────────────────────────
  base: &base
    build:
      context: .
      args: { USE_CUDA: 0 }
    volumes: ["./data:/app/data:ro"]
    environment: [ VALKEY_URL=redis://valkey:6379 ]

  base_gpu: &base_gpu
    build:
      context: .
      args: { USE_CUDA: 1 }
    volumes: ["./data:/app/data:ro"]
    environment: [ VALKEY_URL=redis://valkey:6379 ]
    profiles: ["gpu"]

  # ───────────────────────────── monitoring stack ─────────────────────────────
  prometheus:
    image: prom/prometheus:latest
    command: ["--config.file=/etc/prometheus/prometheus.yml"]
    volumes: ["./prometheus.yml:/etc/prometheus/prometheus.yml"]
    ports: ["9090:9090"]

  grafana:
    image: grafana/grafana-oss:latest
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SECURITY_DISABLE_INITIAL_ADMIN_CHANGE_PASSWORD=true
    ports: ["3000:3000"]
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/etc/grafana/dashboards

  # single exporter → exposes 9121 and covers latency buckets too
  valkey_exporter:
    <<: *base
    command: python agents/valkey_metrics_exporter.py
    ports: ["9121:9121"]
    depends_on: [valkey]

  # ──────────────────────────────── agents ────────────────────────────────────
  enrich:
    <<: *base
    command: python agents/enrich.py
    depends_on: [valkey, prometheus]
    deploy: { replicas: 2 }
    profiles: ["cpu"]

  enrich_gpu:
    <<: *base_gpu
    command: python agents/enrich.py
    depends_on: [valkey, prometheus]
    deploy: { replicas: 2 }
    runtime: nvidia
    profiles: ["gpu"]

  fanout:
    <<: *base
    command: python agents/fanout.py
    depends_on: [valkey, prometheus]

  seed:
    <<: *base
    command: python agents/user_seeder.py
    depends_on: [valkey]

  reader:
    <<: *base
    command: python agents/user_reader.py
    depends_on: [valkey, prometheus]

  replay:
    <<: *base
    command: python agents/replay.py
    environment:
      REPLAY_FILE: data/news_sample.csv
      REPLAY_RATE: "250"
    depends_on: [valkey]

  dashboard:
    <<: *base
    command: python agents/dashboard.py
    ports: ["8501:8501"]
    depends_on: [valkey]

  gateway:
    build: ./api_gateway
    environment: [ VALKEY_URL=redis://valkey:6379 ]
    ports: ["8000:8000"]
    depends_on: [valkey]

  ui_web:
    build: ./ui-react
    ports: ["8500:80"]
    depends_on: [gateway]

  # Scale example:
  #   docker compose up --scale enrich=6 --scale fanout=3 --scale reader=4

